{"cells":[{"cell_type":"code","source":["!pip install azure-eventhub"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4dd2a1cb-40f0-4f7d-b93f-15c537853138"},{"cell_type":"code","source":["import pandas as pd\n","import random\n","from datetime import datetime\n","from pyspark.sql import SparkSession                    \n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n","import pandas as pd\n","import random\n","from datetime import datetime\n","import pytz"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"ee664ce5-2438-4967-b99f-7c91a493ed27","normalized_state":"finished","queued_time":"2025-07-16T11:38:51.7025695Z","session_start_time":null,"execution_start_time":"2025-07-16T11:39:10.8420253Z","execution_finish_time":"2025-07-16T11:39:11.6677733Z","parent_msg_id":"d65211d8-ab4e-4fca-bd1d-3a7d205968fc"},"text/plain":"StatementMeta(, ee664ce5-2438-4967-b99f-7c91a493ed27, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"035c6d39-d913-423f-81a9-221cdf41bf92"},{"cell_type":"code","source":["\n","\n","# Define device to store/location mapping\n","store_mapping = {\n","    (1, 10): (\"Miami\", \"S001\"),\n","    (11, 20): (\"San Diego\", \"S002\"),\n","    (21, 30): (\"New York\", \"S003\"),\n","    (31, 40): (\"San Francisco\", \"S004\"),\n","    (41, 50): (\"Las Vegas\", \"S005\"),\n","    (51, 60): (\"London\", \"S006\"),\n","    (61, 70): (\"Dubai\", \"S007\"),\n","    (71, 80): (\"Singapore\", \"S008\"),\n","    (81, 90): (\"Tokyo\", \"S009\"),\n","    (91, 100): (\"Chicago\", \"S010\"),\n","}\n","\n","# Get current UTC time\n","now_utc = datetime.utcnow()\n","\n","# Generate 100 records\n","records = []\n","for i in range(1, 101):\n","    device_id = f\"TH{i:03}\"\n","    # Determine store and city\n","    for (start, end), (city, store) in store_mapping.items():\n","        if start <= i <= end:\n","            city_name = city\n","            store_id = store\n","            break\n","    # Set values\n","    battery = random.randint(0, 100) \n","    temp = round(random.uniform(60.0, 74.0), 1)\n","    temp_uom = \"F\"\n","    enqueued_time = now_utc\n","    event_processed_time = now_utc\n","    event_enqueued_time = now_utc\n","    partition_id = random.randint(1, 4)\n","\n","    records.append({\n","        \"DeviceId\": device_id,\n","        \"City\": city_name,\n","        \"StoreID\": store_id,\n","        \"EnqueuedTimeUTC\": enqueued_time,\n","        \"BatteryLevel\": battery,\n","        \"Temp\": temp,\n","        \"Temp_UoM\": temp_uom\n","    })\n","\n","# Create DataFrame\n","df = pd.DataFrame(records)\n","\n","# Show first few rows\n","print(df.head())\n","\n","# Optionally save to CSV\n","# df.to_csv(\"thermostat_realtime_data.csv\", index=False)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"715aa3ab-a32e-4b8c-a82d-93658c093e7c"},{"cell_type":"code","source":["\n","\n","# Create Pandas DataFrame\n","df = pd.DataFrame(records)\n","\n","# Convert to Spark DataFrame\n","spark = SparkSession.builder.getOrCreate()\n","\n","schema = StructType([\n","    StructField(\"DeviceId\", StringType(), True),\n","    StructField(\"City\", StringType(), True),\n","    StructField(\"StoreID\", StringType(), True),\n","    StructField(\"EnqueuedTimeUTC\", TimestampType(), True),\n","    StructField(\"BatteryLevel\", IntegerType(), True),\n","    StructField(\"Temp\", FloatType(), True),\n","    StructField(\"Temp_UoM\", StringType(), True)\n","])\n","\n","spark_df = spark.createDataFrame(df, schema=schema)\n","\n","# Write to Lakehouse table\n","#spark_df.write.mode(\"overwrite\").format(\"delta\").option(\"mergeSchema\", \"true\").saveAsTable(\"ThermostatRealtime\")\n","#spark_df.write.mode(\"append\").saveAsTable(\"Thermostat\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"ee664ce5-2438-4967-b99f-7c91a493ed27","normalized_state":"finished","queued_time":"2025-07-16T11:38:51.7065822Z","session_start_time":null,"execution_start_time":"2025-07-16T11:39:11.9753462Z","execution_finish_time":"2025-07-16T11:39:12.8154847Z","parent_msg_id":"c99de5de-ff89-43a4-8221-882f09038ca1"},"text/plain":"StatementMeta(, ee664ce5-2438-4967-b99f-7c91a493ed27, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d055b5cd-d25b-47b7-b41c-6ec24b596b06"},{"cell_type":"code","source":["import json\n","from azure.eventhub import EventHubProducerClient, EventData\n","from datetime import datetime\n","\n","# Custom JSON encoder to handle datetime\n","class DateTimeEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, datetime):\n","            return obj.isoformat()  # Convert datetime to string\n","        return super().default(obj)\n","\n","# Event Hub details\n","CONNECTION_STR = \"#Connection string-primary key#\"\n","EVENT_HUB_NAME = \"#Event hub name#\"\n","\n","\n","# Initialize Event Hub producer\n","producer = EventHubProducerClient.from_connection_string(conn_str=CONNECTION_STR, eventhub_name=EVENT_HUB_NAME)\n","\n","event_data_batch = producer.create_batch()\n","for row in spark_df.collect():\n","    record = row.asDict()\n","    json_payload = json.dumps(record, cls=DateTimeEncoder)  # ✅ Handles datetime\n","    event_data_batch.add(EventData(json_payload))\n","\n","# Send the batch\n","producer.send_batch(event_data_batch)\n","producer.close()\n","\n","print(\"✅ Data sent to Eventstream endpoint.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"ee664ce5-2438-4967-b99f-7c91a493ed27","normalized_state":"finished","queued_time":"2025-07-16T11:38:51.7084894Z","session_start_time":null,"execution_start_time":"2025-07-16T11:39:12.8177397Z","execution_finish_time":"2025-07-16T11:39:13.7320526Z","parent_msg_id":"4ae96f9f-8996-4195-8705-ecbcef182269"},"text/plain":"StatementMeta(, ee664ce5-2438-4967-b99f-7c91a493ed27, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Data sent to Eventstream endpoint.\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce7ec5a9-1645-44a6-b54a-b029a4a0ee73"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}